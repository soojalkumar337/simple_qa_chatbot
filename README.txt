Simple LangChain Chatbot with Groq API 

This project is a simple yet powerful chatbot application built using Streamlit, LangChain, and Groq API.
It demonstrates how to integrate LLMs (LLaMA-3.1 8B Instant) using the langchain_groq package, and how to build a clean conversational UI with Streamlit.

The project is packaged and run using uv (Astralâ€™s ultra-fast Python package manager).

ğŸš€ Features

ğŸ”¹ Streamlit-based web UI

ğŸ”¹ LangChain prompt template

ğŸ”¹ ChatGroq LLaMA-3.1 model integration

ğŸ”¹ .env support for API keys

ğŸ”¹ Clean and minimal chatbot workflow

ğŸ”¹ Runs using uv instead of pip/venv

ğŸ“‚ Project Structure
project/
â”‚â”€â”€ simple_qa_chatbot.py
â”‚â”€â”€ .env
â”‚â”€â”€ uv.lock
â”‚â”€â”€ pyproject.toml
â”‚â”€â”€ README.md

ğŸ”§ Installation & Setup (Using uv)
1ï¸âƒ£ Install uv (if not installed)
pip install uv

2ï¸âƒ£ Clone the Repository
git clone https://github.com/soojalkumar337/simple_qa_chatbot.git
cd simple_qa_chatbot

3ï¸âƒ£ Create .env File

Inside the project folder create a .env file and add:

GROQ_API_KEY=your_api_key_here


5ï¸âƒ£ Start the App
uv run streamlit run app.py

â–¶ï¸ Usage

Run the application.

A browser window will open with the chatbot interface.

Type any question or prompt.

The chatbot responds using Groq LLaMA-3.1 model.

ğŸ§  How It Works

The app loads environment variables using dotenv.

A LangChain prompt template is created:

system message (rules for the model)

user message (input field)

The ChatGroq LLM is initialized with the model:

llama-3.1-8b-instant


A chain is formed using:
Prompt â†’ LLM â†’ OutputParser

Streamlit displays the result in the UI.


ğŸ¤ Contributing

Pull requests are welcome.
For major changes, please open an issue first to discuss what you'd like to change.